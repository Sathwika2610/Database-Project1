{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea38037-44b9-432a-8302-ea9c3a7765c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ea38037-44b9-432a-8302-ea9c3a7765c8",
        "outputId": "ce6a7ea4-0b25-490f-a686-713a55efe8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   StudentID FirstName  LastName   Course  Professor  ProfessorEmail  \\\n",
            "0        101      John       Doe  Math101   Dr.Smith   smith@mst.edu   \n",
            "1        102      Jane       Roe  Math101   Dr.Smith   smith@mst.edu   \n",
            "2        103   Arindam    Khanda    CS101   Dr.Jones   jones@mst.edu   \n",
            "3        104      Jose  Franklin   Bio101  Dr.Watson  watson@mst.edu   \n",
            "4        105       Ada  Lovelace    CS101   Dr.Jones   jones@mst.edu   \n",
            "\n",
            "  CourseStart CourseEnd  \n",
            "0      1/1/23   5/30/23  \n",
            "1      1/1/23   5/30/23  \n",
            "2      2/1/23   6/15/23  \n",
            "3      3/1/23   7/20/23  \n",
            "4      2/1/23   6/15/23  \n",
            "\n",
            "\n",
            "Functional Dependencies\n",
            "{('StudentID',): ['FirstName', 'LastName'], ('Course',): ['CourseStart', 'CourseEnd', 'Professor'], ('Professor',): ['ProfessorEmail']}\n",
            "\n",
            "Select the highest normal form to normalize from the below list \n",
            "1 for 1NF\n",
            "2 for 2NF\n",
            "3 for 3NF\n",
            "B for BCNF\n",
            "4 for 4NF\n",
            "5 for 5NF: 1\n",
            "\n",
            "Determine the highest normal form for the given relation? (1: Yes, 2: No): 1\n",
            "\n",
            "Enter the primary key seperated with commas : StudentID, Course\n",
            "\n",
            "\n",
            "The table is already in 1NF\n",
            "\n",
            "\n",
            "CREATE TABLE StudentID_Course_table (\n",
            "  StudentID VARCHAR(255) PRIMARY KEY,\n",
            "  FirstName VARCHAR(255),\n",
            "  LastName VARCHAR(255),\n",
            "  Course VARCHAR(255) PRIMARY KEY,\n",
            "  Professor VARCHAR(255),\n",
            "  ProfessorEmail VARCHAR(255),\n",
            "  CourseStart VARCHAR(255),\n",
            "  CourseEnd VARCHAR(255)\n",
            ");\n",
            "\n",
            "The Highest Normal Form of the given table is: 1NF\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "from itertools import combinations\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "file = pd.read_csv('sampleInputTable.csv')\n",
        "print(file)\n",
        "print('\\n')\n",
        "\n",
        "with open('fds.txt', 'r') as f:\n",
        "    rows = [row.strip() for row in f]\n",
        "\n",
        "functionaldependencies = {}\n",
        "for row in rows:\n",
        "    determ, depend = row.split(\" -> \")\n",
        "    determ = determ.split(\", \")\n",
        "    functionaldependencies[tuple(determ)] = depend.split(\", \")\n",
        "print('Functional Dependencies')\n",
        "print(functionaldependencies)\n",
        "\n",
        "\n",
        "maximum_normal_form = input(\"\\nSelect the highest normal form to normalize from the below list \\n1 for 1NF\\n2 for 2NF\\n3 for 3NF\\nB for BCNF\\n4 for 4NF\\n5 for 5NF: \")\n",
        "if maximum_normal_form in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
        "    maximum_normal_form = int(maximum_normal_form)\n",
        "\n",
        "find_highest_normal_form = int(\n",
        "    input('\\nDetermine the highest normal form for the given relation? (1: Yes, 2: No): '))\n",
        "high_normalform = 'not normalized'\n",
        "\n",
        "pk = input(\"\\nEnter the primary key seperated with commas : \")\n",
        "primary_key = pk.split(', ')\n",
        "print('\\n')\n",
        "\n",
        "keys = ()\n",
        "keys = tuple(key for key in primary_key)\n",
        "\n",
        "primary_key = keys\n",
        "\n",
        "\n",
        "def check_comma(series):\n",
        "    return any(',' in item for item in series)\n",
        "\n",
        "\n",
        "\n",
        "def input_parser(file):\n",
        "    file = file.astype(str)\n",
        "    columns_with_commas = [\n",
        "        col for col in file.columns if check_comma(file[col])]\n",
        "\n",
        "    for col in columns_with_commas:\n",
        "        file[col] = file[col].str.split(\n",
        "            ',').apply(lambda x: [item.strip() for item in x])\n",
        "\n",
        "    return file\n",
        "file = input_parser(file)\n",
        "\n",
        "multi_value = {}\n",
        "if not maximum_normal_form == 'B' and maximum_normal_form >= 4:\n",
        "    with open('mvd.txt', 'r') as files:\n",
        "        multi_value_dependency_lines = [line.strip() for line in files]\n",
        "\n",
        "    print(multi_value_dependency_lines)\n",
        "\n",
        "    for mvd in multi_value_dependency_lines:\n",
        "        determ, depend = mvd.split(\" ->> \")\n",
        "        determ = determ.split(\n",
        "            \", \") if \", \" in determ else [determ]\n",
        "        determ_str = str(determ)\n",
        "        if determ_str in multi_value:\n",
        "            multi_value[determ_str].append(depend)\n",
        "        else:\n",
        "            multi_value[determ_str] = [depend]\n",
        "\n",
        "\n",
        "def check_is_superkey(rel, determ):\n",
        "    grouped = rel.groupby(\n",
        "        list(determ)).size().reset_index(name='count')\n",
        "    return not any(grouped['count'] > 1)\n",
        "\n",
        "def check_list_or_set(item):\n",
        "    return isinstance(item, (list, set))\n",
        "\n",
        "\"\"\"def powerset(s):\n",
        "    x = len(s)\n",
        "    for i in range(1 << x):\n",
        "        yield [s[j] for j in range(x) if (i & (1 << j)) > 0]\"\"\"\n",
        "\n",
        "\n",
        "def bcnf_decomp(rel, functionaldependencies):\n",
        "    decomposed_rels = [rel]\n",
        "    for determ, depends in functionaldependencies.items():\n",
        "        if set(determ).issubset(rel.columns) and not check_is_superkey(rel, determ):\n",
        "            depend_cols = list(determ) + depends\n",
        "            new_rel1 = rel[depend_cols].drop_duplicates()\n",
        "            remaining_cols = list(set(rel.columns) - set(depends))\n",
        "            new_rel2 = rel[remaining_cols].drop_duplicates()\n",
        "            decomposed_rels = [new_rel for new_rel in decomposed_rels if new_rel is not rel]\n",
        "            decomposed_rels.extend([new_rel1, new_rel2])\n",
        "    return decomposed_rels\n",
        "\n",
        "\n",
        "\n",
        "def is_in_1nf(rel):\n",
        "    if rel.empty:\n",
        "        return False\n",
        "\n",
        "    for column in rel.columns:\n",
        "        if any(isinstance(value, (list, dict, set)) for value in rel[column]):\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "def is_in_2nf(primary_key, functionaldependencies):\n",
        "    for determs, depend in functionaldependencies.items():\n",
        "        superkey = True\n",
        "        for x in determs:\n",
        "            if x not in file.columns:\n",
        "                superkey = False\n",
        "                break\n",
        "        if superkey:\n",
        "            for y in depend:\n",
        "                if y not in file.columns or y not in determs:\n",
        "                    return False\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "def is_in_3nf(rels, functionaldependencies):\n",
        "    all_attributes = set()\n",
        "    for rel in rels:\n",
        "        all_attributes.update(rels[rel].columns)\n",
        "\n",
        "    for determ, depends in functionaldependencies.items():\n",
        "        if all(attr not in all_attributes for attr in determ):\n",
        "            continue\n",
        "        if any(attr in all_attributes for attr in depends):\n",
        "            continue\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "def is_in_bcnf(rels, primary_key, functionaldependencies):\n",
        "    for rel in rels:\n",
        "        for determ, depends in functionaldependencies.items():\n",
        "            if set(determ).issubset(rel.columns):\n",
        "                if not check_is_superkey(rel, determ):\n",
        "                    return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def is_in_4nf(rels, multi_value):\n",
        "    for rel in rels:\n",
        "        for determ, depends in multi_value.items():\n",
        "            if isinstance(determ, tuple):\n",
        "                determ_cols = list(determ)\n",
        "            else:\n",
        "                determ_cols = [determ]\n",
        "\n",
        "            if all(col in rel.columns for col in determ_cols + depends):\n",
        "                grouped = rel.groupby(determ_cols)[\n",
        "                    depends].apply(set).reset_index()\n",
        "                if len(grouped) < len(rel):\n",
        "                    print(f\"violation of multi-valued functional dependencies: {determ} ->> {depends}\")\n",
        "                    return False\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "def is_in_5nf(rels):\n",
        "    candidate_keys_dict = {}\n",
        "\n",
        "    for i, rel in enumerate(rels):\n",
        "        print(rel)\n",
        "        user_input = input(\"Enter the candidate keys : \")\n",
        "        print('\\n')\n",
        "        tuples = re.findall(r'\\((.*?)\\)', user_input)\n",
        "        candidate_keys = [tuple(map(str.strip, t.split(','))) for t in tuples]\n",
        "        candidate_keys_dict[i] = candidate_keys\n",
        "\n",
        "    print(f\"The Candidate Keys for the given relations: {candidate_keys_dict}\\n\")\n",
        "\n",
        "    for j, rel in enumerate(rels):\n",
        "        candidate_keys = candidate_keys_dict[j]\n",
        "        data_tuples = [tuple(row) for row in rel.to_numpy()]\n",
        "\n",
        "        def project(data, attributes):\n",
        "            return {tuple(row[attr] for attr in attributes) for row in data}\n",
        "\n",
        "        def is_superkey(attributes):\n",
        "            return any(set(key).issubset(attributes) for key in candidate_keys)\n",
        "\n",
        "        for i in range(1, len(rel.columns)):\n",
        "            for attrs in combinations(rel.columns, i):\n",
        "                if is_superkey(attrs):\n",
        "                    continue\n",
        "\n",
        "                projected_data = project(data_tuples, attrs)\n",
        "                complement_attrs = set(rel.columns) - set(attrs)\n",
        "                complement_data = project(data_tuples, complement_attrs)\n",
        "\n",
        "                joined_data = {(row1 + row2) for row1 in projected_data for row2 in complement_data}\n",
        "                if set(data_tuples) != joined_data:\n",
        "                    print(f\"Does not satisfy 5NF, check attributes: {attrs}\" )\n",
        "                    return False, candidate_keys_dict\n",
        "\n",
        "    return True, candidate_keys_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def decomposing_to_5nf(dataframe, candidate_keys):\n",
        "\n",
        "    def project(df, attributes):\n",
        "        return df[list(attributes)].drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    def is_lossless(df, df1, df2):\n",
        "        common_columns = set(df1.columns) & set(df2.columns)\n",
        "        if not common_columns:\n",
        "            return False\n",
        "        joined_df = pd.merge(df1, df2, how='inner', on=list(common_columns))\n",
        "        return df.equals(joined_df)\n",
        "\n",
        "    decomposed_tables = [dataframe]\n",
        "\n",
        "    for key in candidate_keys:\n",
        "        new_tables = []\n",
        "        for table in decomposed_tables:\n",
        "            if set(key).issubset(set(table.columns)):\n",
        "                table1 = project(table, key)\n",
        "                remaining_columns = set(table.columns) - set(key)\n",
        "                table2 = project(table, remaining_columns | set(key))\n",
        "\n",
        "                if is_lossless(table, table1, table2):\n",
        "                    new_tables.extend([table1, table2])\n",
        "                else:\n",
        "                    new_tables.append(table)\n",
        "            else:\n",
        "                new_tables.append(table)\n",
        "        decomposed_tables = new_tables\n",
        "\n",
        "    return decomposed_tables\n",
        "\n",
        "\n",
        "def fifth_normalization_form(rels, primary_key, functionaldependencies):\n",
        "    five_rels = []\n",
        "    five_flag, candidate_keys_dict = is_in_5nf(rels)\n",
        "\n",
        "    if five_flag:\n",
        "        return rels, five_flag\n",
        "    else:\n",
        "        i = 0\n",
        "        for rel in rels:\n",
        "            candidate_keys = candidate_keys_dict[i]\n",
        "            i += 1\n",
        "            decomposed_rels = decomposing_to_5nf(rel, candidate_keys)\n",
        "            five_rels.append(decomposed_rels)\n",
        "\n",
        "    return five_rels, five_flag\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fourth_normalization_form(rels, multi_value):\n",
        "    four_rels = []\n",
        "    four_flag = is_in_4nf(rels, multi_value)\n",
        "\n",
        "    if four_flag:\n",
        "        return rels, four_flag\n",
        "    else:\n",
        "        for rel in rels:\n",
        "            for determ, depends in multi_value.items():\n",
        "                for depend in depends:\n",
        "                    if isinstance(determ, tuple):\n",
        "                        determ_cols = list(determ)\n",
        "                    else:\n",
        "                        determ_cols = [determ]\n",
        "\n",
        "                    if all(col in rel.columns for col in determ_cols + [depend]):\n",
        "                        grouped = rel.groupby(determ_cols)[\n",
        "                            depend].apply(set).reset_index()\n",
        "                        if len(grouped) < len(rel):\n",
        "                            table_1 = rel[determ_cols +\n",
        "                                               [depend]].drop_duplicates()\n",
        "                            table_2 = rel[determ_cols + [col for col in rel.columns if col not in [\n",
        "                                depend] + determ_cols]].drop_duplicates()\n",
        "\n",
        "\n",
        "                            four_rels.extend([table_1, table_2])\n",
        "\n",
        "                            break\n",
        "                else:\n",
        "                    continue\n",
        "                break\n",
        "            else:\n",
        "                four_rels.append(rel)\n",
        "\n",
        "    if len(four_rels) == len(rels):\n",
        "        return four_rels\n",
        "    else:\n",
        "        return fourth_normalization_form(four_rels, multi_value)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def third_normalization_form(rels, primary_key, functionaldependencies):\n",
        "    three_rels = {}\n",
        "    original_rel = rels\n",
        "    three_flag = is_in_3nf(rels, functionaldependencies)\n",
        "\n",
        "    if three_flag:\n",
        "        return rels, three_flag\n",
        "    else:\n",
        "        depend_keys = list(functionaldependencies.keys())\n",
        "        for rel in rels:\n",
        "            original_rel = rels[rel]\n",
        "            for determ, depends in functionaldependencies.items():\n",
        "                modified_depends = [\n",
        "                    dep + '_fk' if (dep,) in depend_keys else dep for dep in depends]\n",
        "\n",
        "                cols = list(determ) + depends\n",
        "                three_rels[tuple(determ)] = rels[rel][cols].drop_duplicates(\n",
        "                ).reset_index(drop=True)\n",
        "\n",
        "                rename_dict = {dep: modified_dep for dep,\n",
        "                               modified_dep in zip(depends, modified_depends)}\n",
        "                three_rels[tuple(determ)].rename(\n",
        "                    columns=rename_dict, inplace=True)\n",
        "\n",
        "        junc_cols = []\n",
        "\n",
        "        rel_name = ''\n",
        "        for rel in three_rels:\n",
        "            rel_name += \"_\".join(rel)\n",
        "            junc_cols.append(rel)\n",
        "\n",
        "        if len(junc_cols) > 1:\n",
        "            jun_cols = list(junc_cols)\n",
        "            cols = [element for tup in jun_cols for element in tup]\n",
        "            temp_df = original_rel[cols].drop_duplicates(\n",
        "            ).reset_index(drop=True)\n",
        "\n",
        "            renamed_cols = [col + '_fk' for col in cols]\n",
        "            temp_df.columns = renamed_cols + \\\n",
        "                [col for col in temp_df.columns if col not in cols]\n",
        "\n",
        "            temp_df[rel_name] = range(1, len(temp_df) + 1)\n",
        "            col_order = [rel_name] + renamed_cols\n",
        "            temp_df = temp_df[col_order]\n",
        "            three_rels[rel_name] = temp_df\n",
        "\n",
        "        return three_rels, three_flag\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def bc_normal_form(rels, primary_key, functionaldependencies):\n",
        "    rels = list(rels.values())\n",
        "    bcnf_rels = []\n",
        "    bcnf_flag = is_in_bcnf(rels, primary_key, functionaldependencies)\n",
        "\n",
        "    if bcnf_flag:\n",
        "        return rels, bcnf_flag\n",
        "    else:\n",
        "        for rel in rels:\n",
        "            bcnf_decomp_rel = bcnf_decomp(\n",
        "                rel, functionaldependencies)\n",
        "            if len(bcnf_decomp_rel) == 1:\n",
        "                bcnf_rels.append(bcnf_decomp_rel)\n",
        "            else:\n",
        "                rels.extend(bcnf_decomp_rel)\n",
        "\n",
        "    return bcnf_rels, bcnf_flag\n",
        "\n",
        "\n",
        "\n",
        "def second_normalization_form(rel, primary_key, functionaldependencies):\n",
        "    relations = {}\n",
        "    original_rel = rel\n",
        "    two_flag = is_in_2nf(primary_key, functionaldependencies)\n",
        "\n",
        "    if two_flag:\n",
        "        relations[primary_key] = rel\n",
        "        return relations, two_flag\n",
        "    else:\n",
        "        depend_keys = list(functionaldependencies.keys())\n",
        "        for determ, depends in functionaldependencies.items():\n",
        "            modified_depends = [\n",
        "                dep + '_fk' if (dep,) in depend_keys else dep for dep in depends]\n",
        "\n",
        "            cols = list(determ) + depends\n",
        "            relations[tuple(determ)] = rel[cols].drop_duplicates(\n",
        "            ).reset_index(drop=True)\n",
        "\n",
        "            rename_dict = {dep: modified_dep for dep,\n",
        "                           modified_dep in zip(depends, modified_depends)}\n",
        "            relations[tuple(determ)].rename(\n",
        "                columns=rename_dict, inplace=True)\n",
        "\n",
        "        junc_cols = []\n",
        "        rel_name = ''\n",
        "        for rel in relations:\n",
        "            if set(rel).issubset(primary_key):\n",
        "                rel_name += \"_\".join(rel)\n",
        "                junc_cols.append(rel)\n",
        "\n",
        "        if len(junc_cols) > 1:\n",
        "            jun_cols = list(junc_cols)\n",
        "            cols = [element for tup in jun_cols for element in tup]\n",
        "            temp_df = original_rel[cols].drop_duplicates(\n",
        "            ).reset_index(drop=True)\n",
        "\n",
        "            renamed_cols = [col + '_fk' for col in cols]\n",
        "            temp_df.columns = renamed_cols + \\\n",
        "                [col for col in temp_df.columns if col not in cols]\n",
        "\n",
        "            temp_df[rel_name] = range(1, len(temp_df) + 1)\n",
        "            col_order = [rel_name] + renamed_cols\n",
        "            temp_df = temp_df[col_order]\n",
        "            relations[rel_name] = temp_df\n",
        "\n",
        "\n",
        "        return relations, two_flag\n",
        "\n",
        "\n",
        "\n",
        "def first_normalization_form(rel):\n",
        "    if is_in_1nf(rel):\n",
        "        return rel, True\n",
        "\n",
        "    for col in rel.columns:\n",
        "        if rel[col].apply(check_list_or_set).any():\n",
        "            rel = rel.explode(col)\n",
        "\n",
        "    return rel, is_in_1nf(rel)\n",
        "\n",
        "\n",
        "def output(dtype):\n",
        "    if \"int\" in str(dtype):\n",
        "        return \"INT\"\n",
        "    elif \"float\" in str(dtype):\n",
        "        return \"FLOAT\"\n",
        "    elif \"datetime\" in str(dtype):\n",
        "        return \"DATETIME\"\n",
        "    elif \"object\" in str(dtype):\n",
        "        return \"VARCHAR(255)\"\n",
        "    else:\n",
        "        return \"TEXT\"\n",
        "\n",
        "\n",
        "def sql_query_generator_for_1NF(primary_keys, x):\n",
        "    table_name = \"_\".join(primary_keys) + \"_table\"\n",
        "\n",
        "    query = f\"CREATE TABLE {table_name} (\\n\"\n",
        "\n",
        "    for col, dtype in zip(x.columns, x.dtypes):\n",
        "        if col in primary_keys:\n",
        "            query += f\"  {col} {output(dtype)} PRIMARY KEY,\\n\"\n",
        "        else:\n",
        "            query += f\"  {col} {output(dtype)},\\n\"\n",
        "\n",
        "\n",
        "    query = query.rstrip(',\\n') + \"\\n);\"\n",
        "\n",
        "    print(query)\n",
        "\n",
        "\n",
        "\n",
        "def sql_query_generator_for_2_3(relations):\n",
        "    for rel in relations:\n",
        "        primary_keys = rel\n",
        "        primary_keys = (primary_keys,) if isinstance(primary_keys, str) else primary_keys\n",
        "        table_name = \"_\".join(primary_keys) + '_table'\n",
        "        rel = relations[rel]\n",
        "\n",
        "        query = f\"CREATE TABLE {table_name} (\\n\"\n",
        "\n",
        "        for col, dtype in zip(rel.columns, rel.dtypes):\n",
        "            if col in primary_keys:\n",
        "                query += f\"  {col} {output(dtype)} PRIMARY KEY,\\n\"\n",
        "            elif '_fk' in col:\n",
        "                query += f\" FOREIGN KEY ({col}) REFERENCES {col.replace('_fk','')}_table({col.replace('_fk','')}),\\n\"\n",
        "            else:\n",
        "                query += f\"  {col} {output(dtype)},\\n\"\n",
        "\n",
        "\n",
        "        query = query.rstrip(',\\n') + \"\\n);\"\n",
        "\n",
        "        print(query)\n",
        "\n",
        "\n",
        "def sql_query_generator_for_BCNF_4_5(relations):\n",
        "    for rel in relations:\n",
        "        primary_key = rel.columns[0]\n",
        "        table_name = f'{primary_key}_table'\n",
        "\n",
        "        query = f\"CREATE TABLE {table_name} (\\n\"\n",
        "\n",
        "        for col, dtype in zip(rel.columns, rel.dtypes):\n",
        "            if col == primary_key:\n",
        "                query += f\"  {col} {output(dtype)} PRIMARY KEY,\\n\"\n",
        "            elif '_fk' in col:\n",
        "                query += f\" FOREIGN KEY ({col}),\\n\"\n",
        "            else:\n",
        "                query += f\"  {col} {output(dtype)},\\n\"\n",
        "        query = query.rstrip(',\\n') + \"\\n);\"\n",
        "\n",
        "        print(query)\n",
        "\n",
        "if maximum_normal_form >= 1 or maximum_normal_form == 'B':\n",
        "    onenf_table, one_flag = first_normalization_form(file)\n",
        "\n",
        "    if one_flag:\n",
        "        high_normalform = 'The Highest Normal Form of the given table is: 1NF'\n",
        "\n",
        "    if maximum_normal_form == 1 and one_flag:\n",
        "        print('The table is already in 1NF\\n')\n",
        "        sql_query_generator_for_1NF(primary_key, onenf_table)\n",
        "\n",
        "\n",
        "if maximum_normal_form >= 2 or maximum_normal_form == 'B':\n",
        "    twonf_tables, two_flag = second_normalization_form(onenf_table, primary_key, functionaldependencies)\n",
        "\n",
        "    if maximum_normal_form == 2 and two_flag and one_flag:\n",
        "        print('The table is already in 2NF\\n')\n",
        "        sql_query_generator_for_2_3(twonf_tables)\n",
        "    elif one_flag and two_flag:\n",
        "        high_normalform = 'The Highest Normal Form of the given table is: 2NF'\n",
        "\n",
        "\n",
        "if maximum_normal_form >= 3 or maximum_normal_form == 'B':\n",
        "    threenf_tables, three_flag = third_normalization_form(twonf_tables, primary_key, functionaldependencies)\n",
        "\n",
        "    if one_flag and two_flag and three_flag:\n",
        "        high_normalform = 'The Highest Normal Form of the given table is: 3NF'\n",
        "\n",
        "    if maximum_normal_form == 3 and three_flag and two_flag and one_flag:\n",
        "        print('The table is already in 3NF\\n')\n",
        "\n",
        "    sql_query_generator_for_2_3(threenf_tables)\n",
        "\n",
        "if maximum_normal_form >= 4 or maximum_normal_form == 'B':\n",
        "    bcnf_tables, bcnf_flag = bc_normal_form(threenf_tables, primary_key, functionaldependencies)\n",
        "\n",
        "    if one_flag and two_flag and three_flag and bcnf_flag:\n",
        "        high_normalform = 'The Highest Normal Form of the given table is: BCNF'\n",
        "\n",
        "    if maximum_normal_form == 'B'and bcnf_flag and three_flag and two_flag and one_flag:\n",
        "        print('The table is already in BCNF\\n')\n",
        "\n",
        "    sql_query_generator_for_BCNF_4_5(bcnf_tables)\n",
        "\n",
        "if not maximum_normal_form == 'B' and maximum_normal_form >= 4:\n",
        "    fournf_tables, four_flag = fourth_normalization_form(bcnf_tables, multi_value)\n",
        "\n",
        "    if one_flag and two_flag and three_flag and bcnf_flag and four_flag:\n",
        "        high_normalform = 'The Highest Normal Form of the given table is: 4NF'\n",
        "\n",
        "    if maximum_normal_form == 4 and four_flag and bcnf_flag and three_flag and two_flag and one_flag:\n",
        "        print('The table is already in 4NF')\n",
        "        print('\\n')\n",
        "\n",
        "    sql_query_generator_for_BCNF_4_5(fournf_tables)\n",
        "\n",
        "if not maximum_normal_form == 'B' and maximum_normal_form >= 5:\n",
        "    fivenf_tables, five_flag = fifth_normalization_form(fournf_tables, primary_key, functionaldependencies)\n",
        "\n",
        "    if one_flag and two_flag and three_flag and bcnf_flag and four_flag and five_flag:\n",
        "        high_normalform = 'The Highest Normal Form of the given table is: 5NF'\n",
        "\n",
        "    if maximum_normal_form == 5 and five_flag and four_flag and bcnf_flag and three_flag and two_flag and one_flag:\n",
        "        print('The table is already in 5NF\\n')\n",
        "\n",
        "    sql_query_generator_for_BCNF_4_5(fivenf_tables)\n",
        "\n",
        "if find_highest_normal_form == 1:\n",
        "    print(f\"\\n{high_normalform}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "k2O26Xc7MaWv"
      },
      "id": "k2O26Xc7MaWv"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}